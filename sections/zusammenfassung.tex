\documentclass[../main.tex]{subfiles}

\begin{document}
Diese Arbeit befasst sich mit der Entwicklung von Convolutional Neural Netzworks. Es wurden im Rahmen dieser Studienarbeit vier verschiedene Implementierungen entwickelt, wobei die erste Implementierung als Vorlage der drei anderen Implementierungen diente. Diese hat noch keinerlei Optimierung und läuft lediglich seriell auf einem Kern der CPU ab.

Die anderen drei Implementierungen wurden jeweils für eine spezielle Architektur optimiert. Zum einen gibt es eine Optimierung für x86-Prozessoren wie sie in Arbeitsplatz-PCs und Notebooks vorkommen. Des weiteren gibt es eine Implementierung für CUDA-GPUs. Diese ist für Computer mit Nvidia-Grafikkarten optimiert und führt die Berechnungen auf der GPU anstelle der CPU aus. Eine weitere Implementierung wurde für Server mit einem Intel Xeon Phi-Coprozessor entwickelt. Dabei handelt es sich um eine PCIe-Karte mit einer CPU welche über 50 Kerne besitzt.

Als Testanwendung wurden der MNIST-Datensatz verwendet. Dabei handelt es sich um einen Datensatz welcher 65000 Bildern von handgeschriebenen Ziffern beinhaltet, wovon 55000 für das Trainieren und 10000 für das Verifizieren gedacht sind.

Am Ende erfolgt ein Vergleich zwischen den Implementierungen dieser Arbeit und TensorFlow, einer Bibliothek zum Erstellen von Neuronalen Netzwerken die Google für viele ihrer Dienste verwendet.
\end{document}