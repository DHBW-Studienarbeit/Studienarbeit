\documentclass[../main.tex]{subfiles}

\begin{document}
Diese Arbeit befasst sich mit der Entwicklung von Convolutional Neural Netzworks. Es wurden im Rahmen dieser Studienarbeit vier verschiedene Implementierungen entwickelt, wobei die erste Implementierung als Vorlage der drei anderen Implementierungen diente. Die erste Implementierung wurde als Gruppenarbeit von allen drei Bearbeitern der Studienarbeit erstellt. Diese hat noch keinerlei Optimierung und läuft lediglich seriell auf einem Kern der CPU ab. Für einen produktiven Einsatz ist diese Implementierung deshalb nicht geeignet.

Die anderen drei Implementierungen wurden jeweils für eine spezielle Architektur von einem der Bearbeiter optimiert. Zum einen gibt es eine Optimierung für x86-Prozessoren wie sie in Arbeitsplatz-PCs und Notebooks vorkommen. Des weiteren gibt es eine Implementierung für GPUs mit der CUDA-Programmiertechnik. Diese ist für Computer mit Nvidia-Grafikkarten optimiert und führt die Berechnungen auf der GPU anstelle der CPU aus. Eine weitere Implementierung wurde für Server mit einem Intel Xeon Phi-Coprozessor entwickelt. Dabei handelt es sich um eine PCIe-Karte mit einer CPU welche über 50 Kerne besitzt.

Zum Testen und Trainieren des Netzwerkes wurden der MNIST-Datensatz verwendet. Dabei handelt es sich um einen Datensatz welcher 65000 Bildern von handgeschriebenen Ziffern beinhaltet, wovon 55000 für das Trainieren und 10000 für das Verifizieren gedacht sind. Mit den Trainingsdatensätzen soll ein Netzwerk trainiert werden, welches die anderen Ziffern erkennt, obwohl das Netzwerk diese Bilder nie davor gesehen hat.

Am Ende erfolgt ein Vergleich zwischen den Implementierungen dieser Arbeit und TensorFlow, einer Bibliothek zum Erstellen von Neuronalen Netzwerken die Google für viele ihrer Dienste verwendet, unter anderem für den Google Translator.
\end{document}